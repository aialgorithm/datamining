class Recommendor():
    def __init__(self):
        self.frequencies = {}
        self.deviation = {}
        self.data = {}        
        self.movie_id = {}
        self.convert_movieid()
        self.load_data()
        #print(self.data["4"])
        
    def convert_movieid(self):
        with codecs.open("C:\\doc\\BX-Dump\\ml-latest-small\\ml-latest-small\\movies.csv","r", "utf8") as file_object:
            for line in file_object:
                field = line.split(",")
                self.movie_id[field[0]] = field[1]
           
    def load_data(self):
        movie_dict = {}
        with codecs.open("C:\\doc\\BX-Dump\\ml-latest-small\\ml-latest-small\\ratings.csv","r", "utf8") as file_object:
            for line in file_object:
                field = line.split(",")
                user = field[0]
                movie = self.movie_id[field[1]]
                #print(movie)
                rating = float(field[2])
                movie_dict[movie] = rating
                self.data.setdefault(user,{})
                self.data[user].update(movie_dict)
                movie_dict = {}
                  
    def compute_deviation(self):
        for ratings in self.data.values():
            for item,rating in ratings.items():
                self.frequencies.setdefault(item, {})
                self.deviation.setdefault(item, {})
                for item2,rating2 in ratings.items():
                    if item != item2:
                        self.frequencies[item].setdefault(item2, 0)
                        self.deviation[item].setdefault(item2, 0)
                        self.frequencies[item][item2] += 1
                        self.deviation[item][item2] += rating - rating2            
        for item,ratings in self.deviation.items():
            for item2 in ratings:
                ratings[item2] /= self.frequencies[item][item2]

    #user_base:  分数膨胀pearson相关；数据离散余弦相关；数据密集 曼哈顿距离；
    def user_base_recommendation(self, username): 
        remd_list = []
        knn = 3
        data = self.data
        #k位相似用户
        for user in data:
            if user != username:
                r = self.pearson(data[username], data[user])
                remd_list.append((r, user,data[user]))
        #print (remd_list[0:3])
        remd_list = sorted(remd_list, key=lambda x:x[0], reverse=True)[0:knn]
        #remd_list = sorted(remd_list, key=lambda x:x[0], reverse=True)
        #return remd_list
        #k最邻近算法
        recommend_movie = {}
        remd_sum = 0.0
        for remd in remd_list:
            remd_sum += remd[0]
        if remd_sum == 0:
            return 0
        for remd in remd_list:
            weight = remd[0] / remd_sum
            for k,v in remd[2].items():
                if k not in data[username]:
                    #in 存在判断；= 数值判断；
                    if k not in recommend_movie:
                        recommend_movie[k] = float(v) * weight
                    else :
                        recommend_movie[k] += float(v) * weight
        #print(recommend_movie)
        recommend_movie = sorted(recommend_movie.items(), key=lambda x:x[1], reverse=True)
        #print(recommend_movie)
        return {key:value for key,value in recommend_movie if value > 3}
                                        
    def pearson(self, user_x, user_y):
        x_sum = 0
        y_sum = 0
        xy_sum = 0
        x2_sum = 0
        y2_sum = 0
        n = 0
        r = 0
        for fav_key in user_x:
            if fav_key in user_y:
                if user_x[fav_key] != "" and user_y[fav_key] != "":
                    x_sum += int(user_x[fav_key])
                    y_sum += int(user_y[fav_key])
                    xy_sum += int(user_x[fav_key]) * int(user_y[fav_key])
                    x2_sum += pow(int(user_x[fav_key]), 2)
                    y2_sum += pow(int(user_y[fav_key]), 2)
                    n += 1
        if n == 0:
            return 0
        else:
            fenmu = (sqrt(x2_sum - pow(x_sum, 2) / n) * sqrt(y2_sum - pow(y_sum, 2) / n))
            if fenmu == 0:
                return 0
            else:
                r = (xy_sum - x_sum * y_sum / n) / fenmu
                return r
            
#slope one   为user_a预测item_j的评分：
#遍历每个j对于每个j评分为，遍历user的元素为i，求和user物品i（公有的i，j评分的差异值+user的i评分）*共评分ij的用户数目 
#除以 （求和user物品i们与j的用户数目）
    def slope_one_recommendation(self, user_a):
        self.compute_deviation()
        recommendations = {}
        fenmu = {}
        for useritem,userrating in self.data[user_a].items():
            for diffitem,diffrating in self.deviation.items():
                if diffitem not in self.data[user_a] and useritem in self.deviation[diffitem]:
                    freq = self.frequencies[diffitem][useritem]
                    recommendations.setdefault(diffitem, 0)
                    fenmu.setdefault(diffitem, 0)
                    recommendations[diffitem] += (diffrating[useritem] + userrating) * freq
                    fenmu[diffitem] += freq
        recommendations = [(k, v/fenmu[k]) for (k,v) in recommendations.items()]
        recommendations.sort(key=lambda x:x[1],reverse=True)
        return recommendations[0:20]
    
#修正余弦相似度 遍历user的item_a，为user的每一item_a对比所有的item_b推荐相关性大的：
#遍历所有用户users （u1item_a-u1aver)*(uitem_b-u1aver) /(平方根号得到分子的模)

    def cos_aver(self, item_a, item_b):
        users3 = self.data
        fenzi = 0
        powsum_a = 0
        powsum_b = 0
        aver_dict = {}
        for user in users3:
            score_aver = sum(users3[user].values()) / len(users3[user].values())
            #print("score_aver",score_aver)
            aver_dict[user] = score_aver
            if item_a in users3[user] and item_b in users3[user]:
                #print("ok",users3[user][item_a],users3[user][item_b])
                fenzi += (users3[user][item_a] - aver_dict[user]) * (users3[user][item_b] - aver_dict[user])
                powsum_a += pow((users3[user][item_a] - aver_dict[user]), 2)
                powsum_b += pow((users3[user][item_b] - aver_dict[user]), 2) 
        fenmu = sqrt(powsum_a) * sqrt(powsum_b)        
        if fenmu != 0:
            return fenzi / fenmu


    def cos_recommendation(self, user_a):
    #aver_dict = {}
        users3 = self.data
        s_list = []
        for item_a in users3[user_a] :
            for item_b in self.movie_id.values():
                if item_b != item_a and item_b not in users3[user_a]:
                # print((item_a, item_b))
                    s = self.cos_aver(item_a, item_b)
                    if s :
                        s_list.append((item_a, item_b, s))
        s_list.sort(key=lambda x:x[2],reverse=True)
        return s_list
    

#users2 测试集
users2 = {"Amy": {"Taylor Swift": 4, "PSY": 3, "Whitney Houston": 4},
          "Ben": {"Taylor Swift": 5, "PSY": 2},
          "Clara": {"PSY": 3.5, "Whitney Houston": 4},
          "Daisy": {"Taylor Swift": 5, "Whitney Houston": 3}}

import codecs
from math import sqrt  

r = Recommendor()
r.cos_recommendation('lyy')
r.user_base_recommendation("lyy")
